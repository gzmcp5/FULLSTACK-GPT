{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Ankara\n",
      "        Language: Turkish\n",
      "        Food: Kebab and Baklava\n",
      "        Currency: Turkish Lira"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\n        Here is what I know:\\n        Capital: Ankara\\n        Language: Turkish\\n        Food: Kebab and Baklava\\n        Currency: Turkish Lira')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1 FewShotPromptTemplate\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "t = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "# t = PromptTemplate(\n",
    "#     template=\"What is the capital of {country}\",\n",
    "#     input_variables=[\"country\"]\n",
    "# )\n",
    "\n",
    "t.format(country=\"France\")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# chat.predict(\"What do you know about France?\")\n",
    "\n",
    "# 예제의 형식을 지정하는 방법\n",
    "example_template = \"\"\"\n",
    "    Human: {question}\n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "# example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,                      # 프롬프트 템플릿\n",
    "    examples=examples,                                  # 프롬프트에 입력될 값의 예시\n",
    "    suffix=\"Human: What do you know about {country}?\",  # 형식화된 모든 예제 마지막에 붙일 내용. 보통 사용자의 질문\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "# prompt.format(country=\"Germany\")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\"country\": \"Turkey\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        Capital: Ankara\n",
      "        Language: Turkish\n",
      "        Food: Kebab and Baklava\n",
      "        Currency: Turkish Lira\n",
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n        I know this:\\n        Capital: Ankara\\n        Language: Turkish\\n        Food: Kebab and Baklava\\n        Currency: Turkish Lira\\n        ', additional_kwargs={}, response_metadata={'finish_reason': 'stop'}, id='run--113227df-1326-43d3-a5ca-28175596a853-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.2 FewShotChatMessagePromptTemplate\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "t = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "# t = PromptTemplate(\n",
    "#     template=\"What is the capital of {country}\",\n",
    "#     input_variables=[\"country\"]\n",
    "# )\n",
    "\n",
    "t.format(country=\"France\")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# chat.predict(\"What do you know about France?\")\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"What do you know about {country}?\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "# example_prompt = ChatPromptTemplate.from_template(\"Human: {country}\\nAI: {answer}\")\n",
    "\n",
    "prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,                      # 프롬프트 템플릿\n",
    "    examples=examples,                                  # 프롬프트에 입력될 값의 예시\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert, you give short answers\"),\n",
    "    prompt,\n",
    "    (\"human\", \"What do you know about {country}?\")\n",
    "])\n",
    "\n",
    "# prompt.format(country=\"Germany\")\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"country\": \"Turkey\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about Greece?\\nAI: \\n        I know this:\\n        Capital: Athens\\n        Language: Greek\\n        Food: Souvlaki and Feta Cheese\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Brazil?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.3 LengthBasedExampleSelector\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "t = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "# t = PromptTemplate(\n",
    "#     template=\"What is the capital of {country}\",\n",
    "#     input_variables=[\"country\"]\n",
    "# )\n",
    "\n",
    "t.format(country=\"France\")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# chat.predict(\"What do you know about France?\")\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "\n",
    "# 예제의 형식을 지정하는 방법\n",
    "example_template = \"\"\"\n",
    "    Human: {question}\n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# example_prompt = PromptTemplate.from_template(example_template)\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "# example_selector = LengthBasedExampleSelector(\n",
    "#     examples=examples,\n",
    "#     example_prompt=example_prompt,\n",
    "#     max_length=180,\n",
    "# )\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,                      # 프롬프트 템플릿\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",  # 형식화된 모든 예제 마지막에 붙일 내용. 보통 사용자의 질문\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrrg! Me favorite food be a good ol' plate of salted fish and hardtack! Aye, nothing beats the taste of the sea! Arrr!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrrrg! Me favorite food be a good ol' plate of salted fish and hardtack! Aye, nothing beats the taste of the sea! Arrr!\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.4 Serialization and Composition\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "\n",
    "prompt = load_prompt('./prompt.json')\n",
    "prompt = load_prompt('./prompt.yaml')\n",
    "\n",
    "# prompt.format(country=\"Germany\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant\n",
    "    And you are impersonating a {character}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "    \n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "    \n",
    "    Human: {question}\n",
    "    You:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "    \n",
    "    {example}\n",
    "    \n",
    "    {start}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start)\n",
    "]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final, \n",
    "    pipeline_prompts=prompts\n",
    ")\n",
    "\n",
    "# full_prompt.format(\n",
    "#     character='Pirate',\n",
    "#     example_question='What is your location?',\n",
    "#     example_answer='Arrrrg! That is a secret!! Arg Arg!!',\n",
    "#     question='What is your favorite food?',\n",
    "# )\n",
    "\n",
    "chain = full_prompt | chat\n",
    "chain.invoke({\n",
    "    \"character\":'Pirate',\n",
    "    \"example_question\":'What is your location?',\n",
    "    \"example_answer\":'Arrrrg! That is a secret!! Arg Arg!!',\n",
    "    \"question\":'What is your favorite food?',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n- Water (if needed)\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it is smooth and elastic. If the dough is too dry, add a little water. If it is too wet, add a little more flour.\\n5. Wrap the dough in plastic wrap and let it rest for at least 30 minutes.\\n6. After resting, roll out the dough using a pasta machine or a rolling pin until it is thin.\\n7. Cut the dough into your desired shape, such as fettuccine, spaghetti, or ravioli.\\n8. Cook the pasta in a large pot of salted boiling water for 2-3 minutes, or until al dente.\\n9. Drain the pasta and toss it with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.5 Caching\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "# set_llm_cache(InMemoryCache())\n",
    "# set_debug(True)\n",
    "set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    # streaming=True,\n",
    "    # callbacks=[\n",
    "    #     StreamingStdOutCallbackHandler(),\n",
    "    # ],\n",
    ")\n",
    "\n",
    "chat.predict(\"How do you make Italian pasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- Pinch of salt\\n- Water (if needed)\\n\\nHere is a step-by-step guide to making Italian pasta:\\n\\n1. On a clean work surface, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add a pinch of salt.\\n3. Using a fork, gradually mix the eggs into the flour until a dough forms.\\n4. Knead the dough for about 10 minutes until it becomes smooth and elastic. If the dough is too dry, add a little water. If it is too wet, add a little more flour.\\n5. Wrap the dough in plastic wrap and let it rest for about 30 minutes.\\n6. After resting, divide the dough into smaller portions and roll each portion out into a thin sheet using a rolling pin or pasta machine.\\n7. Cut the dough into your desired shape, such as fettuccine, spaghetti, or ravioli.\\n8. Cook the pasta in a large pot of boiling salted water for 2-3 minutes or until al dente.\\n9. Drain the pasta and toss with your favorite sauce or toppings.\\n\\nEnjoy your homemade Italian pasta!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.predict(\"How do you make Italian pasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients:\n",
      "- 1 cup of rice\n",
      "- 1 cup of water\n",
      "- 1 tablespoon of nuruk (fermentation starter)\n",
      "- 1 tablespoon of sugar\n",
      "\n",
      "Instructions:\n",
      "1. Rinse the rice thoroughly and soak it in water for at least 1 hour.\n",
      "2. Drain the rice and steam it until fully cooked.\n",
      "3. Let the rice cool down to room temperature.\n",
      "4. In a large bowl, mix the nuruk and sugar with the cooked rice.\n",
      "5. Transfer the mixture to a clean glass jar and cover it with a clean cloth.\n",
      "6. Let the mixture ferment in a warm place for 3-4 days, stirring it once a day.\n",
      "7. After 3-4 days, strain the mixture through a cheesecloth to remove any solids.\n",
      "8. Transfer the liquid to a clean bottle and store it in the refrigerator.\n",
      "9. Serve the homemade soju chilled and enjoy responsibly. Ingredients:\n",
      "- 4 cups all-purpose flour\n",
      "- 1 packet active dry yeast\n",
      "- 1 1/2 cups warm water\n",
      "- 2 tablespoons sugar\n",
      "- 2 teaspoons salt\n",
      "- 2 tablespoons olive oil\n",
      "\n",
      "Instructions:\n",
      "1. In a large mixing bowl, combine the warm water, sugar, and yeast. Let it sit for about 5-10 minutes until the yeast is foamy.\n",
      "2. Add the flour, salt, and olive oil to the yeast mixture. Mix until a dough forms.\n",
      "3. Knead the dough on a floured surface for about 5-10 minutes, until it is smooth and elastic.\n",
      "4. Place the dough in a greased bowl, cover with a clean towel, and let it rise in a warm place for about 1-2 hours, or until doubled in size.\n",
      "5. Punch down the dough and shape it into a loaf. Place the loaf in a greased loaf pan.\n",
      "6. Cover the loaf with a clean towel and let it rise for another 30-45 minutes.\n",
      "7. Preheat the oven to 375°F (190°C).\n",
      "8. Bake the bread for 25-30 minutes, or until it is golden brown and sounds hollow when tapped on the bottom.\n",
      "9. Let the bread cool before slicing and serving. Enjoy! \n",
      "\n",
      "Tokens Used: 486\n",
      "\tPrompt Tokens: 27\n",
      "\tCompletion Tokens: 459\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0009585000000000002\n",
      "0.0009585000000000002\n",
      "486\n",
      "27\n",
      "459\n"
     ]
    }
   ],
   "source": [
    "# 4.6 Serialization\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    a = chat.predict(\"What is the recipe for soju\")\n",
    "    b = chat.predict(\"What is the recipe for bread\")\n",
    "    print(a, b, \"\\n\")\n",
    "    print(usage)\n",
    "    print(usage.total_cost)\n",
    "    print(usage.total_tokens)\n",
    "    print(usage.prompt_tokens)\n",
    "    print(usage.completion_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.6 Serialization\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms.openai import OpenAI\n",
    "\n",
    "chat = OpenAI(\n",
    "    temperature=0.1,\n",
    "    max_tokens=450,\n",
    "    model=\"gpt-3.5-turbo-16k\"\n",
    ")\n",
    "\n",
    "chat.save(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giljong-in/Workspace/FULLSTACK-GPT/.venv/lib/python3.11/site-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/giljong-in/Workspace/FULLSTACK-GPT/.venv/lib/python3.11/site-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIChat(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo-16k', model_kwargs={'temperature': 0.1, 'max_tokens': 450, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "chat = load_llm(\"model.json\")\n",
    "\n",
    "chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
