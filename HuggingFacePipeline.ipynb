{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3e0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "How many planets are there? What's their orbital distance? What is the temperature difference between them and their closest neighbours? What is their orbit around the Sun? What are the planets' orbits around their parent stars? What are the moons of their parent planets? What are their moons' moons? What are their moons' moons? What is their planet type? What are the moons of their parent planets? What is their planet type?\n",
      "\n",
      "The most important information about a planet is its orbital distance. It is the distance between\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# from transformers.utils.logging import disable_progress_bar\n",
    "# disable_progress_bar()\n",
    "\n",
    "# model_id = \"gpt2\"\n",
    "# model_id = \"openai-community/gpt2\"\n",
    "# model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "local_path = \"./models/gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(local_path, local_files_only=True)\n",
    "\n",
    "# # pad 토큰 지정 (gpt2의 경우 pad 토큰 없음 → eos 토큰 사용)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # '<|endoftext|>'\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=100,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "hf_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "output = hf_llm.invoke(\"How many planets are there?\")\n",
    "print('==========================')\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
